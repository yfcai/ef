\documentclass{amsart}
\usepackage{bcprules,url,verbatim,multicol,enumerate}
\usepackage[foot]{amsaddr}
\usepackage[utf8x]{inputenc}
\usepackage[greek,english]{babel}

\let\phi=\varphi % default phi looks like empty set
\allowdisplaybreaks
\swapnumbers
\newtheorem{theorem}[subsection]{Theorem}
\newtheorem{lemma}[subsection]{Lemma}
\newtheorem{corollary}[subsection]{Corollary}
\theoremstyle{definition}
\newtheorem{remark}[subsection]{Remark}

\input{macros.tex}

\title{Ideal model for pluggable types}


\def\thingsExpressibleInMpsModel{%
subtyping, universal types, union and intersection types,
recursive types, dependent types, and higher kinds%
}


\begin{document}

\begin{samepage}

\maketitle

\newskip\shrunken
\shrunken=-0.5cm plus 20cm minus 20cm

\begin{table}[h]
\caption{Correspondence between syntactic and semantic objects}
\label{corres}
\end{table}
\vskip\shrunken
% ...
\def\miniwidth{0.4\textwidth}
\renewcommand\arraystretch{1.5}
\begin{tabular}{ll}
\hline Syntactic object \hspace{1cm}\null& Semantic object \\


\hline Term & Value \\


\indent\texttt{plus 3 5} & \indent the number $8$ \\

\indent$\Abs x x$ & \indent identity function on $V$\\

\indent$\Abs f (\Abs x f~(x~x))~(\Abs x f~(x~x))$
&\indent
\begin{minipage}[t]{\miniwidth}\raggedright
the function mapping each $f\in V\R V$ to its least
fixed point, and each $v\notin V\R V$ to~$\Wrong$
\end{minipage}
\vspace{1ex}
\\


\hline Type expression & Mathematical object, possibly a type\\


\indent\texttt{Nat} & \indent$\B N_\bot = \{\bot,0,1,2,\ldots\}$ \\

\indent\texttt{Int} & \indent$\B Z_\bot = \{\bot, 0, 1, -1, 2, -2, \ldots\}$\\

\indent$\texttt{Nat}\R\texttt{Int}$ & \indent$\{f\in (V\R V)_\bot \Or f(\B N_\bot)\subseteq \B Z_\bot\}$ \\

\indent$\All\alpha\alpha\R\alpha$ & \indent$\bigcap_{T\in\Type}\{f\in (V\R V)_\bot \Or f(T) \subseteq T\}$ \\

\indent$\alpha\R\beta$ & \indent
\begin{minipage}[t]{\miniwidth}
A certain mapping from type environments to types
\end{minipage}
\vspace{1ex}
\\


\hline Judgement & Statement \\


\indent\texttt{plus 3 5} : \texttt{Nat} & \indent$8\in\B N_\bot$ \\

\indent $x:\texttt{Nat}\vdash x:\texttt{Nat}$ & \indent
\begin{minipage}[t]{\miniwidth}
If $\rho(x)\in\B N_\bot$, then $\rho(x)\in\B N_\bot$
\end{minipage}\\

\indent
\begin{minipage}[t]{\miniwidth}
$\alpha ; \beta\in[\texttt{Bot},\alpha]\VSub
% $\\\null\hspace{2em}$
\beta\le\beta\R\alpha$
\end{minipage}
&
\indent
\begin{minipage}[t]{\miniwidth}\raggedright
For all $T_\alpha\in\Type$,\\
for all $T_\beta\in\Type$ with
$\{\bot\}\subseteq T_\beta\subseteq T_\alpha$,
we have
${T_\beta\subseteq\{f\in (V\R V)_\bot \Or f(T_\beta)\subseteq T_\alpha\}}$
(It is a false statement.)
\end{minipage}
\vspace{1ex}
\\


\hline Typing rule & Inference rule \\


\begin{minipage}[t]{\miniwidth}\raggedright
\[\frac{
s:\texttt{Nat}\R\texttt{Int}\qquad
t:\texttt{Nat}
}{s~t:\texttt{Int}}\]
\end{minipage}
&
\indent
\begin{minipage}[t]{\miniwidth}\raggedright
If the term $s$ denotes $f\in\{g\Or g(\B N_\bot)\subseteq \B
Z_\bot\}$ and\\
$t$ denotes $v\in \B N_\bot$, then draw the conclusion that
$s~t$ denotes $f(v)\in Z_\bot$.
\end{minipage}
\vspace{1ex}\\\hline
\end{tabular}

\end{samepage}

\newpage
\setcounter{tocdepth}1
\tableofcontents

\section{Pros and cons}

Bracha (Pluggable type systems) advocates that the type system of
a language should be optional and should not affect the
language's runtime behavior. There are several benefits to such
an arrangement.
\begin{enumerate}
\item A useful program can be executed even if it has no type.
\item Type systems can evolve faster than the language itself.
\item Type inference can be made optional as well, so that the
expressiveness of the type system is not bounded by the power of
the inference algorithm.
\end{enumerate}
We demonstrate a technique of pluggable types for purely
functional languages. It achieves all of the above and more:
\begin{enumerate}\setcounter{enumi}3
\item It is safe for type systems to work together. The composite
of several sound subsystems will continue to reject all programs
with runtime type errors.
\item Types defined in different subsystems can interact with
each other. It is possible to call library functions defined in
another type system.
\end{enumerate}
The technique is applicable to a wide variety of type systems. It
can express \thingsExpressibleInMpsModel.

There are some restrictions on what a type can be. For example,
if a program~$f$ has type $T$, then $T$ must admit every program
that terminates less often than $f$ but behaves otherwise in the
same way. Our types cannot separate terminating programs from
nonterminating ones.

The technique guarantees nothing about the type checker's
performance; it may run forever. Writing a nonterminating type
checker is as easy as writing a nonterminating program in Java.
It remains to investigate how to compose non-brute-force type
checkers in a modular and scalable way.

\section{Background}

A runtime type error occurs when a value is used in an unintended
manner, such as adding an integer and a truth value,
dereferencing a non-pointer, and calling a non-function. A type
system is \emph{sound} if no well-typed program encounters
runtime type errors. Soundness is one of the most important
design goals of type systems.

There are several methods to prove a type system sound. We will
discuss two: the syntactic approach, and the domain-theoretic
approach.

\Par{The syntactic approach}

It is the current standard framework for soundness proofs.
\begin{enumerate}
\item Capture the runtime behavior of the language in a
small-step semantics such that terms with runtime type errors are
\emph{stuck}: Neither are they values, nor can they reduce to
other terms.
\item Demonstrate \emph{progress}: A well-typed term is either a
value or reduces to something else.
\item Demonstrate \emph{preservation}: If a term has type $\tau$
then it continues to have type $\tau$ after one reduction.
\end{enumerate}
Together, progress and preservation imply that well-typed terms
never get stuck, and thus cannot experience runtime type errors.

In most circumstances, we can ``append'' to a syntactic soundness
proof to accommodate new runtime behaviors without modifying
existing arguments. But we cannot take two systems proven sound
by the syntactic approach, take the union of their typing rules,
and expect soundness to hold for the result. The two syntactic
soundness proofs gave us progress and preservation for terms
typed with rules in one single system; they say nothing about
terms typed with a mixture of rules from both systems.

\Par{The domain-theoretic approach}

\begin{enumerate}
\item Capture the runtime behavior of the language in a Scott
domain.
\item Define types as certain sets of values in the semantic
domain. Designate a special value $\Wrong$ for runtime type
errors, and make sure it is not a member of any type.
\item Construct an interpretation from terms to values in the
semantic domain. Show that if a term $t$ has type $\tau$, then
$t$ interprets to a member of $\tau$.
\end{enumerate}
Since no type contains $\Wrong$, well-typed programs do not
denote $\Wrong$, and their evaluation may not encounter runtime
type errors.

A domain-theoretic soundness proof is not extensible with new
runtime behaviors. Adding mutation to a purely functional
language, for example, requires a completely new domain. The old
arguments have to be rewritten, because their foundation---the
old domain equation---has become obsolete.

However, if we extend the type system without modifying the
runtime behavior, then we can keep interpreting terms into the
old semantic domain. If the new typing rules are sound on their
own, then they already meet the expectation of the old soundness
proof, namely that they assign type $\tau$ only to terms
interpreting to a member of $\tau$. In this way, the old proof
carries over even to terms typed with a mixture of old and new
rules, and type soundness continues to hold.

If types are pluggable, then the language's runtime behavior has
to stay constant in all possible type systems. Here, a
domain-theoretic type soundness proof is more extensible than a
syntactic proof.


\section{Roadmap}

To achieve safely pluggable types, we exploit the extensibility
of domain-theoretic type soundness proofs when the runtime system
never changes. These are the steps:
\begin{enumerate}
\item Choose a semantic domain. For purely functional languages,
a domain for untyped lambda calculus suffices.
\item Choose a theory of types for the semantic domain. We employ
the ideal model by MacQueen, Plotkin and Sethi. It can easily
express \thingsExpressibleInMpsModel.
\item Develop type systems such that each typing rule corresponds
to a true statement in the theory of types. This property often
follows from the domain-theoretic soundness proof and incurs no
effort beyond that.
\end{enumerate}
Thus typing rules become lemmas, judgements become statements,
and typing derivations become proofs. Typing terms with a mixture
of type systems is no more than writing proofs with a larger
collection of lemmas.

The next section rephrases the ideal model of types by MacQueen
et al. (Ideal model for recursive polymorphic types) in a more
modern framework, so as to avoid using 2 different notions of
limit in the semantic domain.

The section after that describes how to make type systems
pluggable.

The other sections give examples of pluggable type systems. We
will look at System~F, unboxed impredicative polymorphism, and
optional type arguments. It will be interesting to explore
subtyping, continuations, mutation, dependent types and higher
kinds.


\section{Ideal model of types}

This section recounts the ideal model of types by MacQueen et
al.\ (Ideal model for recursive polymorphic types) with modern
notions. After an informal overview of the most important
concepts, we will work toward a proof that recursive types are
well-defined. The next section starts on
page~\pageref{after-domain-theory}.

\Par{Informal overview}

The domain $V$ contains values denoted by terms of untyped lambda
calculus. It satisfies the isomorphism
\begin{align}
\label{domain-eq}
V&\simeq (V\R V)+B+\{\bot,\Wrong\},
\end{align}
where $+$ is disjoint union, $(V\R V)$ is the set of
``continuous'' functions from $V$ to $V$, $B$ is the set of base
values (usually numbers, truth values and strings), $\bot$ is the
value of nonterminating programs, and $\Wrong$ signifies runtime
type errors. Let us assume implicit conversion between $V$ and
$B$, $(V\R V)$ etc., so that we may treat base values, functions,
$\bot$ and $\Wrong$ as if they were actual values in $V$ and save
space.

Types are sets of values under certain closure conditions. The
operator $\RT$ constructs a type from two types.
\begin{align*}
\Type &= \text{set of subsets of $V$ that are types}\\
T_1\RT T_2 &= \{f\in V
\Or
f=\bot\quad\text{or}\quad
f\in V\R V\text{ and }f(T_1)\subseteq T_2
\}
\end{align*}

Let us state the definition of types for future reference. A
subset $T\subseteq V$ is a~type if it is a nonempty closed set
under the Scott toplogy and $\Wrong\notin T$.

\Par{Domain-theoretic background}
\label{domain-theory}

Here we list facts from domain theory. Some results will depend
on the particular construction of $V$ as a \emph{consistently
complete algebraic cpo}, but we will not go into details.
Chapters 2--4 of Stoltenberg-Hansen et al.\ (Mathematical Theory
of Domains) contain a careful development.

There is a \emph{definedness} partial order $\Sub$ on $V$ such
that
\begin{itemize}
\item [D1.] $\bot\Sub v$ for all $v\in V$,
\item [D2.] a base value in $B$ is only comparable with $\bot$ and
itself,
\item [D3.] if $f,g\in V\R V$, then $f\Sub g$ if and only if $f(v)\Sub
g(v)$ for all $v\in V$.
\end{itemize}

A set $A\subseteq S$ is \emph{directed} if $A$ is nonempty and
for all $x,y\in A$ there exists $z\in A$ such that $x\Sub z$ and
$y\Sub z$. Intuitively, a directed set contains successive
approximations of the same value.

A partially ordered set is a \emph{cpo} (complete partial order)
if its every directed subset has a supremum. $V$ is a cpo.

\begin{samepage}
There is a topology on $V$ called the \emph{Scott topology}.
A set $S\subseteq V$ is \emph{open} in the Scott topology if
\begin{itemize}
\item $S$ is \emph{upward-closed}: $v\in S$ whenever $u\Sub v$
for some $u\in S$, and
\item $S$ is \emph{unreachable by directed limit}: $\sup A\notin
S$ for every directed set $A$ disjoint from $S$.
\end{itemize}
\end{samepage}

\begin{samepage}
A set $T\subseteq V$ is \emph{closed} if its complement $V-T$ is
open. $T$ is closed if and only if
\begin{itemize}
\item $T$ is \emph{downward-closed}: $u\in T$ whenever $u\Sub v$
for some $v\in T$, and
\item $T$ is \emph{closed under directed limit}: $\sup A\in T$
for every directed set $A\subseteq T$.
\end{itemize}
\end{samepage}

A subset $T\subseteq V$ is a \emph{type} if $T$ is a nonempty
closed set and $\Wrong\notin T$. Both downward-closure and
closure under directed limit are necessary to establish that each
recursive type equation is satisfied by a unique type. For
example, one and only one type satisfies the following version of
Curry's paradox:
\[
T=T\RT \{\bot\}.
\]
It allows us to type $\Omega$ with recursive types (folklore on
Haskell mailing list):
\[
(\Abs{x : \mu\alpha. \alpha\R\Bot}x~x)~
(\Abs{x : \mu\alpha. \alpha\R\Bot}x~x).
\]
Closure under directed limit is a natural strengthening of the
\emph{admissibility} criterion for contracts in HALO (Haskell to
logic through denotational semantics). In fact, all contracts
described in HALO can be strengthened to types by imposing
downward-closure without disturbing the theories surrounding
them.

Scott topology satisfies the 3 axioms of topology:
\begin{itemize}
\item $\emptyset$ and $V$ are open,
\item the union of an arbitrary family of open sets are open,
\item the intersection of finitely many open sets is open.
\end{itemize}

On the flip side,
\begin{itemize}
\item the intersection of an arbitrary family of types is a type,
\item the union of finitely many types is a type.
\end{itemize}

A function $f$ from $V$ to $V$ is \emph{continuous} if for every
open set $S\subseteq V$, the preimage $f^{-1}(S)$ is an open set.
The function $f$ is continuous if and only if
\begin{itemize}
\item $f$ is \emph{monotone}: $f(u)\Sub f(v)$ whenever $u\Sub v$,
and
\item $f$ \emph{preserves directed limits}: $\sup f(A) = f(\sup
A)$ for every directed $A\subseteq V$.
\end{itemize}
Write $V\R V$ for the set of continuous functions from $V$ to
$V$. The domain equation~\eqref{domain-eq} states that a subset
of $V$ is isomorphic to the set of continuous functions on $V$.

A value $v\in V$ is \emph{compact} if for all directed set $A$
with $v\Sub\sup A$, there exists $a\in A$ such that $v\Sub a$. A
compact element of $V$ is either $\bot$, $\Wrong$, a base value,
or a function $f$ such that there exists compact values
$u_1,v_1,\ldots,u_n,v_n$ and $f$ is the least function mapping
each $u_i$ to $v_i$. Informally, all information about a compact
function lies within a finite number of argument-result pairs.
This characterization of compact elements is a corollary of
theorem~3.8 in chapter~3 on page~67 of Stoltenberg-Hansen et al.\
(Mathematical Theory of Domains).

A cpo is \emph{algebraic} if every element is the supremum of a
directed set of compact elements. $V$ is an algebraic cpo. In
particular, the behavior of every function in $V\R V$ is
determined by its value on compact elements. This agrees with the
intuition that a terminating higher-order function $f$ can only
call its argument~$g$ finitely many times. Even if $g$ is more
complex than finite collections of argument-result pairs, $f$
cannot detect that extra complexity and cannot reflect it in
$f(g)$.

Since $V$ is algebraic, every closed set is completely determined
by its compact elements. In particular, if $T_1$ and $T_2$ are
distinct types, then there exists a compact element that belongs
to one and not the other.

A cpo is \emph{consistently complete} if every set of elements
have a supremum whenever they are bounded above. $V$ is
consistently complete.

These are all the concepts necessary to comprehend the statement
``$V$ is a consistently complete algebraic cpo.''


\Par{Rank of compact elements}

MacQueen et al.\ (Ideal model for recursive polymorphic types)
proposed the notion of \emph{rank} of compact elements so as to
define the distance between types and discuss the convergence of
sequences of types. They presented the domain $V$ as some limit
of $V_0,V_1,\ldots$, where
\begin{align*}
V_0 &= \{\bot\},\\
V_1 &= (V_0\R V_0)+B+\{\bot,\Wrong\},\\
&\vdots\\
V_n &= (V_{n-1} \R V_{n-1}) + B + \{\bot,\Wrong\},\\
&\vdots
\end{align*}
and defined the rank of a compact element $v$ as the number $i$
such that $v$ ``appears'' in $V_i$ for the first time. It is
possible to formalize this intuition in terms of commuting
embedding-projection pairs between each $V_i$ and $V$ akin to
those described in \S12.3 on page~319 of Stoltenberg-Hansen et
al.\ (Mathematical theory of domains). We will not discuss the
formalities in detail, only list the relevant properties of the
rank function.
\begin{itemize}\itemsep=1ex
\item[R1.] $\bot$ has rank 0.

\item[R2.] Base values in $B$ and $\Wrong$ have rank 1.

\item[R3.] A function $f\in V\R V$ has rank at most $n$ if and
only if there exists a set~$P$ of value pairs of rank at most
$n-1$ such that $f$ is the least function satisfying $f(x)=y$ for
all $(x,y)\in P$.

\item[R4.] If $f\in V \R V$ does not have rank $n$ for every
$n\in\mathbb N$, then $f$ has rank $\infty$.

\item[R5.] Every compact element has finite rank.
\end{itemize}
Properties R1--4 can be regarded as a practical definition of
rank. R5 is a consequence of theorems 6.5~and 6.7 in chapter~4 on
page~107 of Stoltenberg-Hansen et al.\ (Mathematical Theory of
Domains).

The next lemma exercises the properties of rank and will be used
in \S\ref{contract-fun}.

\begin{lemma}
\label{sup-rank}
Let $S\subseteq V$ be a set of rank-$n$ elements. If\/ $S$ has an
upper bound in $V$, then $\sup S$ exists and has rank at most $n$.
\end{lemma}

\begin{proof}
Since $S$ has an upper bound in $V$, either $S$ is disjoint from
$V\R V$ or is a subset of it.

\emph{Case} $S\cap(V\R V)=\emptyset$. If $S$ has no rank-1
element, then $S\subseteq\{\bot\}$ and $\sup S=\bot$. If $S$ has a rank-1
element $v$, then $v$ is maximal in $V$ and has to be the upper
bound of $S$. Thus $v=\sup S$.

\emph{Case} $S\subseteq V\R V$. Let $g\in V$ be an upper bound of
$S$. By R3, for each $v\in S$ there exists a set $P_v$ of
argument-result pairs of rank at most $n-1$ such that $v$ is the
least function agreeing with $P_v$. Let
\begin{align*}
P &= {\textstyle\bigcup_{v\in S}} P_v,\\
f(x) &= \sup\ \{y' \Or (x',y')\in P\text{ and } x'\Sub x \}.
\end{align*}
Since $g$ is an upper bound of $S$, each set $\{y' \Or (x',y')\in
P\text{ and } x'\Sub x \}$ is bounded above by $g(x)$ and has a
supremum in $V$ by consistent completeness. Thus $f$ is
well-defined. By property~D3 of the definedness partial order,
$f$ is the least upper bound of $S$. By R4, $f$ has rank $\le n$.
\end{proof}


\Par{Metric space of types}

Recall from \S\ref{domain-theory} that types are nonempty closed
sets excluding $\Wrong$. Following MacQueen et al.\ (Ideal model
for recursive polymorphic types), we will define a distance
function between types so that they form a metric space.

Let $T_1,T_2$ be types. If $T_1=T_2$, then their \emph{proximity}
is $\infty$. If $T_1\neq T_2$, then their proximity is the
smallest rank among \emph{compact} elements in the symmetric
difference
\[
T_1 \operatorname\triangle T_2 = (T_1 - T_2)\cup (T_2 - T_1).
\]
The proximity of two types signifies how hard it is to tell them
apart. No two types have proximity~0, because $\bot$ is a member
of all types. It is easiest to tell types of proximity~1 apart,
because they are separated by a visible base value. If a
function~$f$ separates two types, then we will have a hard time
verifying it if we have to call $f$ on many complicated arguments
before arriving at some visible evidence.

The distance $d(T_1, T_2)$ between types $T_1, T_2$ is inverse
exponential in the types' proximity.
\begin{align}
\label{distance}
d(T_1,T_2)
&=\frac{1}{2^{\mathrm{proximity}(T_1,T_2)}}
\end{align}
The distance function $d$ satisfies the conditions required of
one in a metric space:
\begin{enumerate}\itemsep=1ex
\item [M1.] $d(T_1,T_2)\ge0$.
\item [M2.] $d(T_1,T_2)=0$ if and only if $T_1=T_2$.
\item [M3.] $d(T_1,T_2)=d(T_2,T_1)$.
\item [M4.] $d(T_1,T_3)\le d(T_1,T_2)+d(T_2,T_3)$.
\end{enumerate}
M1 is obvious. M2 follows from algebraicity of $V$, as all pairs
of distinct types are separated by a compact element, which has
finite rank. M3 follows from symmetry of symmetric difference. To
see M4, let $v$ be the least-ranked compact element separating $T_1$ and
$T_3$. Assume without loss of generality that $v\in T_3-T_1$. If
$v\in T_2$, then $d(T_1,T_3)\le d(T_1, T_2)$. If $v\notin T_2$,
then $d(T_1, T_3)\le d(T_2, T_3)$.

\Par{Cauchy sequences, convergence and closure}

An infinite sequence of types $T_1,T_2,\ldots$ is Cauchy if for
every $\epsilon>0$ there exists $n\in\mathbb N$ such that for all
$i,j\ge n$, the distance between $T_i$~and $T_j$ is smaller than
$\epsilon$.

A sequence $T_1,T_2,\ldots$ of types \emph{converges} to the
\emph{limit} $T$ if for all $\epsilon>0$, there exists
$n\in\mathbb N$ such that for all $i\ge n$ we have
$d(T,T_n)<\epsilon$.

Let $S$ be an arbitrary subset of $V$. The \emph{closure} of $S$
is the smallest closed set containing $S$:
\[
\Closure(S) = {\textstyle\bigcap}\{S' \Or S\subseteq S'\text{ and
}S'\text{ is closed}.\}
\]

\begin{lemma}
\label{closure}
If $S\subseteq V$ is downward-closed, then there is no compact
element in $\Closure(S)-S$.
\end{lemma}

\begin{proof}
For each $v\in V$, define the \emph{upset} $v\Up$ of $v$ as follows:
\[
v\Up = \{u\in V \Or v\Sub u\}.
\]
By example~1.4(ii) in chapter~5 on page~117 of Stoltenberg-Hansen
et al.\ (Mathematical Theory of Domains), the upsets of compact
elements form a \emph{base} of the Scott topology. In other
words, every open set is the union of upsets of some compact
elements. Let
\[
R = {\textstyle\bigcup}\{v\Up \Or v\notin S\text{ and $v$ is compact}\}.
\]
Clearly $R$ is open. If $\Closure(S)=V-R$, then every compact
element $v$ in $\Closure(S)-S$ would satisfy both $v\notin R$ and
$v\notin S$, which is impossible. We argue $\Closure(S)=V-R$ by
showing that $V-R$ is the smallest closed set containing $S$. We
know $V-R$ is closed because $R$ is open. $V-R$ is a superset of
$S$ because $R\cap S=\emptyset$ by downward closure of $S$.
Let $S'$ be a closed set containing $S$. Then $V-S'$ is open.
Since upsets of compact elements form a topological base,
\begin{align*}
V-S' &= {\textstyle\bigcup}\{v\Up \Or v\in \overline S_c'\}&\mbox{where}\\
\overline S_c' &= \{v\in V \Or v\notin S'\text{ and $v$ is compact}\}.
\end{align*}
Since $S\subseteq S'$,
\[
\overline S_c' \subseteq
\{v\in V \Or v\notin S\text{ and $v$ is compact}\},
\]
which means $V-S'\subseteq R$, or equivalently, $V-R\subseteq S'$.
\end{proof}

\begin{theorem}\label{cauchy}
Every Cauchy sequence of types converges.
\end{theorem}

\begin{proof}
This corresponds to theorem~1 of MacQueen et al.\ (Ideal model
for recursive polymorphic types). Let $T_1,T_2,\ldots$ be a
Cauchy sequence of types. Let
\[
T =
\Closure({\textstyle \bigcup_{n=1}^\infty\bigcap_{i=n}^\infty} T_i).
\]
We will show that $T$ is a type, and that $T_i$ is arbitrarily
close to $T$ for all $i$ large enough.

$T$ is a type if $T$ is closed, nonempty and excludes $\Wrong$.
$T$ is closed by construction. Since each $T_n$ is nonempty and
downward closed, $\bot\in T_n$ for all $n\in\mathbb N$. Thus
$\bot\in T$, and $T$ is nonempty. Since $V-\{\Wrong\}$ is a
closed set containing all $T_i$, it is a superset of $T$.

To show that $T$ is arbitrarily close to $T_i$, choose
$\epsilon>0$. Since $T_1,T_2,\ldots$ are Cauchy, there exists
$n\in\mathbb N$ such that for all $j,k\ge n$,
\[
d(T_j,T_k)<\epsilon/2.
\]
Therefore for all $i\ge n$,
\begin{align*}
d(T_i, T_{\ge i}) &< \epsilon/2&\mbox{where}\\
T_{\ge i} &= {\textstyle\bigcap_{j=i}^\infty} T_j.
\end{align*}
If $d(T, T_{\ge i})\ge\epsilon/2$, then there exists a compact
element $v\in T-T_{\ge i}$ such that $\Rank(v)\le-\log_2\epsilon
+ 1$. By lemma~\ref{closure},
\[
v\in({\textstyle \bigcup_{n=1}^\infty\bigcap_{j=n}^\infty} T_j) -
T_{\ge i},
\]
which means there exists $j,k\ge i$ such that $v\in T_j-T_k$.
Then $d(T_j,T_k)\ge\epsilon/2$, a~contradiction. Hence
\begin{align*}
d(T,T_{\ge i})&<\epsilon/2\hspace{3cm}\mbox{and}\\
d(T,T_i)&<d(T_i,T_{\ge i})+d(T_{\ge i},T)<\epsilon.
\end{align*}
\end{proof}

\Par{Banach fixed-point theorem}

A metric space is \emph{complete} if all Cauchy sequences
converge. By theorem~\ref{cauchy}, the metric space of types is
complete.

A function $F$ mapping types to types is \emph{nonexpansive} if
there exists $0\le q\le1$ such that for all types $T_1,T_2$,
\[
d(f(T_1), f(T_2)) \le q \, d(T_1, T_2).
\]
If $q<1$, then $F$ is \emph{contractive}.

The Banach fixed-point theorem states that every contractive
function on a nonempty complete metric space has a unique fixed
point. Therefore a recursive type equation $T=F(T)$ defines a
unique type if $F$ is contractive. In the next few paragraphs, we
will show record, variant and function type constructions to be
contractive, substantiating the claim that recursive algebraic
data types are well-defined.

\Par{KISP: composing binary type operators}
\label{kisp}

We want to show record, variant and function type constructions
to be contractive even when nested to arbitrary depth. The KISP
framework in Yakushev et al.\ (Generic programming with fixed
points for mutually recursive data types) provides a good
structure to the argument. KISP stands for the type-level
combinators $K$, $I$, sum and product, which are sufficient to
express all strictly positive algebraic data types. Instead of
sum and product, we will use combinators lifted from $\RT$, union
and intersection, so as to support recursion in contravariant
positions as well.

Suppose we want to establish that a unique type $T_*$
satisfies
\[
T_*=(T_*\RT \mathbb Z_\bot)\RT \mathbb Z_\bot.
\]
For that, we need to demonstrate contraction of the type-level
function $F$ mapping each $T$ to $(T \RT \mathbb Z_\bot)\RT
\mathbb Z_\bot$. Let us express $F$ in point-free style:
\begin{align*}
F &= (I \RL K(\mathbb Z_\bot)) \RL K(\mathbb Z_\bot)
\end{align*}
where
\begin{align*}
I(T) &= T \\
K(T_1)(T_2) &= T_1 \\
(F_1 \RL F_2)(T) &= F_1(T) \RT F_2(T)\\
(F_1 \Cup F_2)(T) &= F_1(T) \cup F_2(T)\\
(F_1 \Cap F_2)(T) &= F_1(T) \cap F_2(T)
\end{align*}
The lifted union and intersection will be relevant later for
records and variants. We can show contraction of $F$---or of
other type functions built with the five combinators above---with
the following lemma.

\begin{samepage}
\begin{lemma}
\label{kisp}
~
\begin{itemize}
\item [L1.] $K(T)$ is contractive for all $T$.
\item [L2.] $I$ is nonexpansive.
\item [L3.] If $F$ and $G$ are nonexpansive, then $F\RL G$ is
contractive.
\item [L4.] If $F$ and $G$ are nonexpansive, then $F\Cup G$ and
$F\Cap G$ are nonexpansive. If $G$ and $G$ are contractive, then
$F\Cup G$ and $F\Cap G$ are contractive.
\end{itemize}
\end{lemma}
\end{samepage}

$K(T)$ is contractive because it takes all distances to 0. $I$ is
nonexpansive because it preserves distance. For L3 and L4,
imagine $H$ to be a~binary type operator like $\RT$, $\cup$ or
$\cap$. If $H$ is nonexpansive in both arguments, then the type
combinator lifted from $H$ preserves nonexpansion and
contraction. Such is the case in L4. If $H$ is contractive in
both arguments, then the type combinator lifted from $H$ takes
two nonexpansive type functions to a contractive one. Such is the
case in L3. We will prove neither the preceding remarks nor the
nonexpansion of union and intersection, because I do not think
they are hard and do not know how to present them in an
interesting way. The next theorem discusses contraction of $\RT$.


\begin{theorem}
\label{contract-fun}
The binary type operator~$\RT$ is contractive in both arguments.
\end{theorem}

\begin{proof}
We will only prove contraction of $\RT$ in its contravariant
first argument; the case for the covariant second argument is
similar. Let
\[
f\in(A\RT C)-(B\RT C)
\]
be the least-ranked element in the symmetric difference between
$A\RT C$ and $B\RT C$. There exists a pair of elements $x,y\in V$
such that $x\in B-A$, $y\notin C$ and $f(x)=y$. Let $n$ be the
rank of $f$. There exists a set $P$ of argument-result pairs of
rank at most $n-1$ such that $f$ is the least function agreeing
with $P$. Let
\begin{align*}
X &= \{x' \Or x'\Sub x\text{ and }(x', y')\in P\text{ for some }y'\},\\
Y &= \{y' \Or (x',y')\in X\text{ for some }x'\}.
\end{align*}
$X$ and $Y$ have supremums because $x$ is an upper bound of $X$
and $y$ is an upper bound of $Y$. Since $f$ is least,
\[
y = f(x) = \sup Y = f(\sup X).
\]
Since $\sup X\Sub x$ and $B$ is downward closed, we have $\sup
X\in B$. If $\sup X\in A$, then $f(\sup X)=y\notin C$ contradicts
the fact that $f\in A\RT C$. Therefore $\sup X$ is in the
symmetric difference between $A$ and $B$. By
lemma~\ref{sup-rank}, the rank of $\sup S$ is at most $n-1$. Thus
\[
d(A\RT C,B\RT C)=\frac1{2^n}=\frac12\cdot\frac1{2^{n-1}}
\le\frac12\cdot\frac1{2^{\Rank(\sup X)}}\le\frac12\,d(A, B).
\]
\end{proof}


\Par{Contraction of record and variant constructions}

Using lemma \ref{kisp}~and theorem~\ref{contract-fun}, we can
encode record and variant constructions into type functions and
show them to be contractive.

For each value $v\in V$, write
\[
v\Down = \{u\in V \Or u \Sub v\}.
\]
Clearly $v\Down$ is a type. The record type
$
\{\texttt{real}:\mathbb R_\bot,\texttt{img}:\mathbb R_\bot\}
$
is encoded as intersection of function types
\[
(\texttt{"real"}\Down~\RT~\mathbb R_\bot)
\cap(\texttt{"img"}\Down~\RT~\mathbb R_\bot),
\]
where \texttt{"real"} and \texttt{"img"} are string literals. In
general, record types are encoded thus:
\[
\{l_i:T_i~^{1\le i \le n}\}
=
\bigcap_{i=1}^n l_i\Down~\RT~T_i.
\]
If all $F_i$ are nonexpansive, then the function taking $T$ to
$\{l_i:F_i(T)\}$ is contractive by L3 and L4 of lemma~\ref{kisp}.

The variant type $\langle\texttt{rational}:\mathbb
Q_\bot,\texttt{irrational}:\mathbb R_\bot\rangle$ is encoded as
the union of intersections of function types
{\def\Raise{\raisebox{0pt}[2.1ex][0pt]{}}
\begin{align*}
&\left(\Raise
(\texttt{"tag"}\Down~\RT~\texttt{"rational"})
\cap
(\texttt{"content"}\Down~\RT~\mathbb Q_\bot)
\right)\\
&\cup~
\left(\Raise
(\texttt{"tag"}\Down~\RT~\texttt{"irrational"})
\cap
(\texttt{"content"}\Down~\RT~\mathbb R_\bot)
\right).
\end{align*}}%
Since the strings \texttt{"rational"} and \texttt{"irrational"}
are maximal in $V$, no maximal value can be both variants at the
same time. In general,
\[
\langle l_i:T_i~^{1\le i\le n}\rangle =
\bigcup_{i=1}^n~
(\texttt{"tag"}\Down~\RT~l_i\Down)
~\cap~
(\texttt{"content"}\Down~\RT~T_i).
\]
Just like record types, the function taking $T$ to $\langle
l_i:F_i(T)\rangle$ is contractive if each $F_i$ is nonexpansive.

This encoding of records and variants has structural subtyping.
If we want to make algebraic data types ``disjoint'' as they are
in Haskell, we need only add the name of the data type as a field
to every constructor.


\Par{Beyond algebraic data types}

We have shown that the recursive type $\mu\alpha.~\sigma$ is
well-defined if $\sigma$ is built from record, variant and
function type constructions. In a language with universal types
such as System~F, We may want to allow types like
\begin{align*}
&\mu\alpha.~\alpha\R(\All\beta\beta\R\alpha)
&\mbox{or}&
&\All\alpha\alpha\R(\mu\beta.~\beta\R\alpha).
\end{align*}
Proving them well-defined involves reasoning about more than one
bound variable at a time, which requires a more powerful
framework than KISP.

Write
\[
T_1 \Times T_2 = \{\texttt{fst} : T_1, \texttt{snd} : T_2\}.
\]
To encode dependent vectors of real numbers, we might attempt to
take the infinite union
\[
\def\Unit{\mathit{Unit}}
\def\Real{\mathbb R_\bot}
(0\Times\Unit)\cup(1\Times\Real)\cup
(2\Times\Real\Times\Real)\cup(3\Times\Real\Times\Real\Times\Real)\cup\cdots.
\]
Although the arbitrary union of types is not always a type, there
exists a smallest type containing the sets
$(0\Times\mathit{Unit})$, $(1\Times\mathbb R_\bot)$ etc.\ that we
can take as the type of dependent vectors. This is a consequence
of example~1.4(ii) in chapter~5 on page~117 of Stoltenberg-Hansen
et al.\ (Mathematical Theory of Domains).


\Par{The importance of being pluggable}

We have seen that the ideal model can express function types,
records, variants, recursive types and dependent types. With such
power, why do we need pluggable types at all? Why not a
monolithic type system to mirror the ideal model exactly?
MacQueen et al.\ (Ideal model for recursive polymorphic types)
states that it is undecidable to check whether an untyped lambda
term denotes a member of any given type. While I lack the
expertise to verify, it seems reasonable to assume that the
undecidability result would survive the port of the ideal model
to consistently complete algebraic cpos. If this is the case,
then we may never enjoy a complete type checker for the ideal
model, but only use fragments of it appropriate to the situation
at hand.


\section{How to craft pluggable types}
\label{howto}


\label{after-domain-theory}


We have learnt the notion of types, the nature of function types,
and the construction of recursive types. We will see how to make
type systems pluggable.

Our core language is untyped lambda calculus with constants. Its
standard denotational semantics serves as the interface to the
runtime system modeled by the value domain $V$. Each lambda term
denotes a value in $V$ under a term environment~$\env$, which
maps variables to values in $V$.

\begin{syntax}
t & ::= & &\mbox{untyped lambda term} \\
& & c &\mbox{constant} \\
&|& x &\mbox{variable} \\
&|& \Abs xt &\mbox{abstraction} \\
&|& t~t &\mbox{application}
\end{syntax}
%
\begin{align*}
\Sem c~\env &= v_c & \mbox{designated value for constant }c\\
\Sem x~\env &= \env(x) & \mbox{variable look-up}\\
\Sem{\Abs x t}~\env &=
\rlap{function mapping $v\in V$ to $\Sem t~(\Update\env{x\mapsto v})$}\\
\Sem{t_1~t_2}~\env &=
\begin{cases}
\bot&\rlap{if $\Sem{t_1}~\env=\bot$}\\
f(v)&\rlap{if $\Sem{t_1}~\env=f\in V\R V$ and $\Sem{t_2}~\env=v$}\\
\Wrong&\rlap{if $\Sem{t_1}~\env\notin \{\bot\}\cup(V\R V)$}
\end{cases}
\end{align*}

A pluggable type system may rely on syntax extensions. Each
extended term must ``erase'' to an untyped lambda term, so that
the runtime knows how to execute it. A syntax extension may be an
optional type annotation, such as one on the argument of a lambda
abstraction.
\begin{syntax}
\sigma & ::= & \cdots & \mbox{type expression}\\
t & \+= & \Abs{x:\sigma}t & \mbox{annotated abstraction}\\
\Erase(\Abs{x:\sigma}t) & = & \Abs x \Erase(t) &
\mbox{erasure to core language}
\end{syntax}

Type expressions have no core syntax; they are not even required
to denote a type. For our purpose of ruling out runtime errors,
it suffices that \emph{some} type expressions denote types. A
type expressions of System~F denotes a type only if it is
\emph{closed}, when all its type variables are universally
quantified somewhere. Table~\ref{corres} on page~\pageref{corres}
contains more examples of type expressions.

Pluggable type systems produce \emph{Judgements.} Judgements are
abbreviations of mathematical statements. To treat statements as
concrete data, we can represent them by well-formed formulas of
ZFC (Zermelo-Fraenkel set theory with the axiom of choice). Each
pluggable type system is free to produce its own flavor of
judgements, but all systems should strive to eventually produce
T-judgements, or typing judgements about closed terms.
\begin{syntax}
J_0
& ::=
& t : \sigma
   & \mbox{typing judgement about a closed term} \\
&& & \mbox{where $t$ is closed and $\sigma$ denotes a type}
\end{syntax}%
The judgement $t:\sigma$ abbreviates ``The value denoted by $t$
under the empty environment is a member of the type denoted by
$\sigma$.'' We say a closed term $t$ is \emph{well-typed} if the
type system in use can produce some T-judgement $t:\sigma$.
Since $\Wrong$ is not a member of any type, well-typed
expressions do not denote $\Wrong$.

A pluggable type system produces judgements according to a
collection of \emph{typing rules}. In fact, we can think of the
type system \emph{as} the collection of typing rules. A typing
rule is an inference rule in the style of natural deduction. Each
rule has zero or more antecedents, zero or more side conditions,
and one conclusion. The antecedents are judgements, the side
conditions are statements (i.~e., well-formed formulas of ZFC),
and the conclusion is a judgement. A typing rule corresponds to
the statement ``If all antecedents and side conditions are true,
then the conclusion is true.'' We call a typing rule \emph{sound}
if it corresponds to a provable statement. Sound typing rules are
admissible with respect to the axioms and inference rules of ZFC
(Does this claim need justification?). The typing rule in the
last row of table~\ref{corres} on page~\ref{corres} is sound.

Judgements are produced by \emph{derivations.} A derivation is a
natural deduction proof: a finite tree built from instances of
typing rules, where the antecedents of every rule instance
coincide with the conclusions of instances immediately above it,
and all side conditions are true. The final conclusion is the
product of the derivation. If the typing rules are sound, then
the product of every derivation has a proof in ZFC. A pluggable
type system is \emph{sound} if all its typing rules are sound. A
sound type system only produces true judgements.

We mix several type systems together by taking union of their
typing rules. The mixture of sound type systems is clearly sound.
If it produces the T-judgement $t:\sigma$, then we are
certain that $t$ denotes an element of some type, which cannot be
$\Wrong$. In this sense, mixing pluggable type systems preserves
type safety.

We know a term $t$ never raises runtime type errors if some
typing derivation produces a T-judgement about $t$. It does
not matter how the typing derivation is produced. A practical
implementation of a pluggable type system may be incomplete
without compromising type safety. The type checker may reject
some terms by mistake and loop forever on others, but the terms
it does accept are guaranteed to be type safe. Since the type
system is extensible, writing code with an incomplete type
checker will not create maintenance hell in the future. The
programmer can start using a type system without waiting for its
type checker to become complete and decidable.



\section{Warm-up example: System~F}

We will phrase System~F in the framework outlined in
\S\ref{howto} so that it can be used together with other type
systems. This particular semantic model of System~F was sketched
in Girard (System~F of variable types: fifteen years later,
\S3.1).

\Par{Syntax extension}

System~F requires annotated abstraction, type abstraction and
type application. The interpretation of any term with these
extensions is identical to the interpretation of its erasure.

\begin{syntax}
t &\+=& &\mbox{syntax extension} \\
&& \Abs{x:\sigma}t &\mbox{annotated abstraction}\\
&|& \Tabs\alpha t &\mbox{type abstraction}\\
&|& t~[\sigma] &\mbox{type application}
\end{syntax}%

\begin{align*}
\Erase(\Abs{x:\sigma}t) & = \Abs x\Erase(t) \\
\Erase(\Tabs\alpha t) &= \Erase(t) \\
\Erase(t~[\sigma]) &= \Erase(t)
\end{align*}

\Par{Type expressions}
\label{open-types}

\begin{syntax}
\sigma &::=& &\mbox{open type expression}\\
&& \iota &\mbox{base type}\\
&|& \alpha &\mbox{type variable}\\
&|& \sigma\R\sigma &\mbox{function type}\\
&|& \All\alpha\sigma &\mbox{universal type}
\end{syntax}%

\Par{Interpretation of open types}
\label{interp-open-types}

A type environment $\Env$ is a \emph{total}%
%
\footnote{%
If we allowed type environments to be partial functions, then
many typing judgements would have to begin with ``for every type
environment defined on all relevant type variables.''
%
} %
function mapping type variables to types. An open type denotes a
function mapping type environments to types.

\begin{align*}
\Sem\iota~\Env &= T_\iota \subseteq B\hspace{2cm}\mbox{designated base type}\\
\Sem\alpha~\Env &= \Env(\alpha)\\
\Sem{\sigma_0\R\sigma_1}~\Env &= (\Sem{\sigma_0}~\Env)\ \RT\ (\Sem{\sigma_1}~\Env)\\
&=\{\bot\}\cup\{f\in V\R V\Or f(\Sem{\sigma_0}~\Env)\subseteq\Sem{\sigma_1}~\Env\}\\
\Sem{\All\alpha\sigma}~\Env &=
\bigcap_{T\in\Type} \Sem\sigma~(\Update\Env{\alpha\mapsto T})
\end{align*}

If an open type expression $\sigma$ has no free type variable,
then we say $\sigma$ is \emph{closed} and denotes the
type~$\Sem\sigma~\Env_\bot$, where $\Env_\bot$ is the type
environment mapping every type variable to $\{\bot\}$.


\Par{Judgements}

\begin{syntax}
\Gamma &::=&& \mbox{typing context}\\
&& \emptyset &\mbox{empty context}\\
&|&\Gamma,x:\sigma &\mbox{term variable binding}\\
\\\\
\JF &::=
&\Gamma\vdash t:\sigma
& \mbox{F-judgement}
\end{syntax}


\Par{Interpretion of F-judgements}

Write
\[
\Sem\Gamma~\Env =
\{
\env\Or
\env(x)\in\Sem\sigma~\Env\text{ for all }
x:\sigma\in\Gamma
\}.
\]
If $\env\in\Sem\Gamma~\Env$, then we say that the term
environment $\env$ is \emph{compatible} with the typing context
$\Gamma$ under the type environment $\Env$.

The F-judgement $\Gamma\vdash t:\sigma$ abbreviates the
following statement.
\begin{quotation}
For every type environment $\Env$ and every $\env\in\Sem\Gamma~\Env$,
\[
\Sem{t}~\env~\in~\Sem\sigma~\Env.
\]
\end{quotation}~


\Par{Typing rules of Pluggable~F}~

\infrule[T-F]
{\emptyset\vdash t:\sigma\andalso t,\sigma\text{ closed}}
{t:\sigma}

\infrule[F-Con]
{v_c\in \Sem\sigma~\Env\andalso\sigma\text{ closed}}
{\Gamma\vdash c:\sigma}

\infrule[F-Var]
{x:\sigma\in\Gamma}
{\Gamma\vdash x:\sigma}

\infrule[F-Abs]
{\Gamma,x:\sigma_1\vdash t:\sigma_2
\andalso x\notin\Gamma}
{\Gamma\vdash\Abs{x:\sigma}t : \sigma_1\R\sigma_2}

\infrule[F-App]
{\Gamma\vdash t_1:\sigma_2\R\sigma_3
\andalso\Gamma\vdash t_2:\sigma_2}
{\Gamma\vdash t_1~t_2:\sigma_3}

\infrule[F-Tabs]
{\Gamma\vdash t:\sigma\andalso\alpha\notin\FTV(\Gamma)}
{\Gamma\vdash\Tabs\alpha t:\All\alpha\sigma}

\infrule[F-Tapp]
{\Gamma\vdash t:\All\alpha\sigma_0}
{\Gamma\vdash t~[\sigma_1]:\sigma_0[\alpha\mapsto\sigma_1]}


\Par{Soundness of Pluggable~F}
\label{sound-F}

We outline the proof of each statement corresponding to a typing
rule of Pluggable~F.

\textsc{T-F}: Since $t$ and $\sigma$ are closed, they denote a
value $v_t$ and a type $T_\sigma$ under whatever environments.
The antecedent says $v_t\in T_\sigma$; the conclusion says the
same thing.

\textsc{F-Con}: Since $c$ and $\sigma$ are both closed, their
denotations do not depend on type or term environments. The
conclusion is a consequence of the first side condition.

\textsc{F-Var}: The
side condition implies that no matter which term environment
$\env$ compatible with $\Gamma$ is chosen, the value $\env(x)$
must be a member of the type $\Sem\sigma~\Env$. The conclusion
follows.

\textsc{F-Abs}: Write $T_1=\Sem{\sigma_1}~\Env$ and
$T_2=\Sem{\sigma_2}~\Env$. By the antecedent, $t$ denotes a value
in $T_2$ under every environment $\env$ that is compatible with
$\Gamma$ and maps $x$ to a member of $T_1$. It follows that the
denotation of $\Abs xt$ under every environment compatible with
$\Gamma$ is a function whose image of $T_1$ is a subset of $T_2$.

\textsc{F-App}: The antecedents say that under every
compatible environment, $t_1$ denotes a function $f$ whose image
of $\Sem{\sigma_2}~\Env$ is a subset of $\Sem{\sigma_3}~\Env$,
and $t_2$ denotes a value $v\in\Sem{\sigma_2}~\Env$. As desired,
$f(v)\in\Sem{\sigma_3}~\Env$.

\textsc{F-Tabs}: Let $\env$ be an arbitrary term environment
compatible with $\Gamma$ under $\Env$. Let $v=\Sem{t}~\env$.
For every type $T\in\Type$, the antecedent guarantees that
\[
v\in\Sem\sigma~(\Update\Env(\alpha\mapsto T)),
\]
which implies
\[
v\in\bigcap_{T\in\Type}\Sem\sigma~(\Update\Env(\alpha\mapsto T))
=\Sem{\All\alpha\sigma}~\Env.
\]

\textsc{F-Tapp}: Let $\env$ be a term environment compatible with
$\Gamma$ under $\Env$. Write
\begin{align*}
T_1&=\Sem{\sigma_1}~\Env,\\
v&=\Sem{t}~\env.
\end{align*}
By the antecedent,
\[
v\in
\bigcap_{T\in\Type}\Sem{\sigma_0}~(\Update\Env(\alpha\mapsto T))
\ \subseteq\ \Sem{\sigma_0}~(\Update\Env\alpha\mapsto T_1).
\]
By the correctness of capture-avoiding substitution,
\[
\Sem{\sigma_0}~(\Update\Env\alpha\mapsto T_1)
=
\Sem{\sigma_0[\alpha\mapsto\sigma_1]}~\Env,
\]
which gives us $v\in\Sem{\sigma_0[\alpha\mapsto\sigma_1]}~\Env$
as desired.


\section{Constrained type system version 1}

To demonstrate what pluggable types are possible, we present a
novel type system CT1 (Constrained Type System Version 1). It
supports the impredicative universal types of System~F, but does
not demand type arguments from the user. The metatheory of CT1 is
far from mature. We do not know whether it can type all terms
that are typeable in System~F with extra type arguments, or
whether it admits a terminating type checking algorithm. Since
CT1 is pluggable, however, we can start reaping its the benefit
without waiting for metatheoretic development. If it so happened
that CT1 could not handle certain useful programs, then we need
only import a new type system to deal with those, confident that
any legacy code typed under CT1 will continue to enjoy strong
type soundness.

\Par{Syntax extension}

\begin{syntax}
t &\+=& \Abs{x:\sigma}t &\mbox{annotated abstraction}\\
&|& \Tabs\alpha t &\mbox{type abstraction}
\end{syntax}%

\begin{align*}
\Erase(\Abs{x:\sigma}t) & = \Abs x\Erase(t)\\
\Erase(\Tabs\alpha t) &= \Erase(t)
\end{align*}

\Par{Type expressions}

CT1 divides type expressions into two camps. If I am a~value,
left types stand for what I am, right types stand for what I
aspire to be. Open type expressions (\S\ref{open-types}) are both
left and right. We divide the left from the right to confine
union types to the left hand side of any subtype constraint, and
intersection types to the right hand side. This way, every
subtype constraint on compound types can be expressed as the
conjunction of constraints on simpler types.

\begin{syntax}
\rho &::=& &\mbox{left type expression}\\
&& \iota &\mbox{base type}\\
&|& \alpha &\mbox{type variable}\\
&|& \tau \R \rho &\mbox{left function type}\\
&|& \All\alpha\rho &\mbox{left universal type}\\
&|& \Bot & \mbox{smallest type}\\
&|& \rho\cup\rho &\mbox{union of left types}\\
&|& \All{\alpha\in I}\rho &\mbox{interval-bounded universal type}\\
\\\\
\tau &::=& &\mbox{right type expression}\\
&& \iota & \mbox{base type}\\
&|& \alpha &\mbox{type variable}\\
&|& \rho \R \tau &\mbox{right function type}\\
&|& \All\alpha\tau &\mbox{right universal type}\\
&|& \Top &\mbox{largest type}\\
&|& \tau\cap\tau &\mbox{intersection of right types}\\
\\\\
I &::=& [\rho, \tau] &\mbox{type interval}
\end{syntax}%

\Par{Interpretation of type expressions}
\label{interp-ct-types}

Left and right type expressions have the same interpretation as
open types; they are mappings from type environments to types.
Recall that the union of two types is a type.
\begin{align*}
\Sem\Bot~\Env &=\{\bot\}\\
\Sem{\rho_1\cup\rho_2}~\Env &= (\Sem{\rho_1}~\Env) \cup
(\Sem{\rho_2}~\Env)\\
%
\Sem\Top~\Env &=V-\{\Wrong\}\\
\Sem{\tau_1\cap\tau_2}~\Env &= (\Sem{\tau_1}~\Env) \cap
(\Sem{\tau_2}~\Env)
\end{align*}
The interpretation of base types, left/right function types and
left/right universal types are identical to the interpretation of
base types, function types and universal types in open type
expressions (\S\ref{interp-open-types}). Left and right type
expressions can be regarded as extension-refinements of open type
expressions, where the constructors $\R$~and $\forall$ retain
their meanings.

A type interval interprets to a set of types sandwiched between
its lower and upper bounds. If the lower bound is not a subset of
the upper bound, then the type interval interprets to the empty
set.
\begin{align*}
\Sem{[\rho,\tau]}~\Env &= \{T\in\Type\Or
\Sem{\rho}~Env\ \subseteq\ T\ \subseteq\ \Sem{\tau}~Env\}
\end{align*}
An interval-bounded universal type interprets to the intersection
of a family of types indexed by members of the interval.
\begin{align*}
\Sem{\All{\alpha\in I}\rho}~\Env &=
\begin{cases}
\displaystyle\bigcap_{T\in(\SemSlim I~\Env)}
\Sem\rho~(\Update\Env\alpha\mapsto T)
&\text{if}\quad\Sem I~\Env\neq\emptyset,
\\[2em]
V-\{\Wrong\}
&\text{if}\quad\Sem I~\Env=\emptyset.
\end{cases}
\end{align*}

\Par{Judgements}

CT1 produces two species of judgements. The S-judgements are
about relative containment between types, and the CT-judgements
are conditional statements about the membership of values in
types. Typing contexts are identical to those in System~F.

\begin{syntax}
\Gamma &::=&\emptyset& \mbox{typing context}\\
&|&\Gamma,x:\sigma\\
\\\\
E & ::= & \emptyset & \mbox{prefix of interval bounds}\\
&|&E,\alpha\in I\\
\\\\
C & ::= &\emptyset& \mbox{S-constraints}\\
&|& C,\rho\le\tau\\
\\\\
\JCT & ::= & \Gamma\vdash t:\rho\Given C
&\mbox{CT-judgement}\\
\\\\
\JS & ::= & E\vdash C & \mbox{S-judgement}
\end{syntax}

\Par{Interpretation of CT- and S-judgements}
A type environment $\Env$ satisfies the list of constraints $C$
if for each $\rho_i\le\tau_i\in C$,
\[
\Sem{\rho_i}~\Env\ \subseteq\ \Sem{\tau_i}~\Env.
\]

The CT-judgement $(\Gamma\vdash t:\rho\Given C)$ abbreviates:
\begin{quotation}
For every $\Env$ satisfying $C$ and every
$\env\in\Sem\Gamma~\Env$,
\[
\Sem t~\env\ \in\ \Sem\rho~\Env.
\]
\end{quotation}

Let $E=\beta_1\in I_1,\ldots,\beta_n\in I_n$ be an arbitrary
prefix of interval bounds. A type environment $\Env$ is
\emph{compatible} with $E$ if for all $1\le j\le n$ we have
\[
\Env(\beta_j)\ \in\ \Sem{I_j}~\Env.
\]
(See \S\ref{interp-ct-types} for the meaning $\Sem{I_j}~\Env$.
Note that $\Env$ appears on both sides of the membership relation.)

\begin{samepage}
Define \emph{well-formed prefixes} recursively thus:
\begin{itemize}
\item $\emptyset$ is well-formed.
\item If $E$ is well-formed, $\alpha$ is a fresh type variable,
and $\Sem I~\Env\neq\emptyset$ for every $\Env$ compatible with
$E$, then $(E,\alpha\in I)$ is well-formed.
\end{itemize}
\end{samepage}


\begin{samepage}
The S-judgement $E\vdash C$ abbreviates:
\begin{quotation}
$E$ is well-formed. Every $\Env$ compatible with $E$ satisfies $C$.
\end{quotation}
\end{samepage}


\Par{CT-rules of CT1}~

% handle top-level sigs by type ascription in next section
% no need for sub0 here
\infrule[T-CT]
{\emptyset\vdash t:\rho\Given\emptyset\andalso
t,\rho\text{ closed}}
{t:\rho}

\infrule[CT-Con]
{v_c\in \Sem\rho~\Env\andalso\rho\text{ closed}}
{\Gamma\vdash c:\rho \Given \emptyset}

\infrule[CT-Var]
{x:\sigma\in\Gamma}
{\Gamma\vdash x:\sigma\Given\emptyset}

\infrule[CT-Abs]
{\Gamma,x:\sigma\vdash t:\rho\Given C
\andalso x\notin\Gamma}
{\Gamma\vdash\Abs{x:\sigma}t : \sigma\R\rho\Given C}

\infrule[CT-App]
{\Gamma\vdash t_1:\rho_1\Given C_1
\andalso\Gamma\vdash t_2:\rho_2\Given C_2
\andalso\alpha,\beta\text{ fresh}
}
{\Gamma\vdash t_1~t_2:\beta
\Given C_1\cup C_2,\rho_1\le\alpha\R\beta,\rho_2\le\alpha
}

\infrule[CT-Tabs]
{\Gamma\vdash t:\rho\Given C\andalso
\alpha\notin\FTV(\Gamma)\cup\FTV(C)}
{\Gamma\vdash\Tabs\alpha t:\All\alpha\rho\Given C}

\infrule[CT-S]
{
\Gamma\vdash t:\rho\Given C
\andalso
\beta_1\in I_1,\ldots,\beta_n\in I_n\vdash C
\andalso
\beta_1,\ldots,\beta_n\notin\FTV(\Gamma)
}
{\Gamma\vdash t :
\All{\beta_1\in I_1}\cdots\All{\beta_n\in I_n}\rho
\Given\emptyset}

\Par{Soundness of CT-rules}
\label{sound-CT}

We outline the proof of each statement corresponding to a
constrained typing rule of CT1.

\textsc{T-CT}: Since $t$ and $\sigma$ are closed, they denote a
value $v$ and a type $T$ under whatever environments. The
antecedent states that $v\in T$ under a vacuously true condition,
so we may conclude $v\in T$.

\textsc{CT-Con} and \textsc{CT-Var}: Analogous to \textsc{F-Con}
and \textsc{F-Var} discussed in \S\ref{sound-F}.

\textsc{CT-Abs}: Let $\Env$ be a type environment satisfying $C$.
If $\Env$ does not exist, then the conclusion is vacuously true.
If $\Env$ exists, then let $\env$ be compatible with $\Gamma$
under $\Env$. Write
\begin{align*}
T_\sigma&=\Sem{\sigma}~\Env,\\
T_\rho&=\Sem{\rho}~\Env,\\
f&=\Sem{\Abs x t}~\env.
\end{align*}
Choose arbitrary $v\in T_\sigma$. Since
\[
(\Update\env x\mapsto v)\ \in\ \Sem{\Gamma,x:\sigma}~\Env,
\]
the antecedent implies $f(v)\in T_\rho$, and we may conclude
$f\in T_\sigma \RT T_\rho$.

\textsc{CT-App}: Let $\Env$ be a type environment satisfying
$C_1\cup C_2,\rho_1\le\alpha\R\beta,\rho_2\le\alpha$. Choose
arbitrary $\env\in\Sem\Gamma~\Env$. Write
\begin{align*}
T_1&=\Sem{\rho_1}~\Env,&
v_1&=\Sem{t_1}~\env,\\
T_2&=\Sem{\rho_2}~\Env,&
v_2&=\Sem{t_2}~\env.
\end{align*}
Since $\Env$ satisfies $\rho_1\le\alpha\R\beta$ and
$\rho_2\le\alpha$,
\begin{align*}
T_1&\subseteq \Env(\alpha)\RT\Env(\beta), &
T_2&\subseteq \Env(\alpha).
\end{align*}
Since $\Env$ satisfies both $C_1$ and $C_2$, the antecedents give
us
\begin{align*}
v_1&\in T_1 \subseteq \Env(\alpha)\RT\Env(\beta), &
v_2&\in T_2 \subseteq \Env(\alpha),
\end{align*}
which yield $v_1(v_2)\in\Env(\beta)$ as desired.

\textsc{CT-Tabs}: Similar to \textsc{T-Tabs} discussed in
\S\ref{sound-F}.

\textsc{CT-S}: The assumed S-judgement $\beta_1\in
I_1,\ldots,\beta_n\in I_n\vdash C$ states that the prefix of
interval bounds
\[
E=\beta_1\in I_1,\ldots,\beta_n\in I_n
\]
is well-formed, and that every type environment compatible with
$E$ satisfies $C$. Consider an arbitrary type environment
$\Env$. Let
\begin{align}
\notag
T&=\Sem{\All{\beta_1\in I_1}\cdots\All{\beta_n\in I_n}\rho}~\Env\\
&=
\bigcap_{T_1\in\SemSlim{I_1}~\Env}
\qquad
\bigcap_{T_2\in\SemSlim{I_2}~(\Update\Env\beta_1\mapsto T_1)}
\cdots
\notag\\
&\hspace{0.5cm}\cdots
\bigcap_{T_n\in\SemSlim{I_n}~(\Update\Env
\beta_1\mapsto T_1,\ldots,
\beta_{n-1}\mapsto T_{n-1}
)}
\label{nested-monstrosity}
\\[1em]
&\hspace{2cm}
\Sem\rho~(\Update\Env
\beta_1\mapsto T_1,\ldots,\beta_n\mapsto T_n).
\notag
\end{align}
Note that in~\eqref{nested-monstrosity}, all index sets of the
form
\[
\Sem{I_j}~(\Update\Env\beta_1\mapsto T_1,\ldots,
\beta_{j-1}\mapsto T_{j-1})
\]
are nonempty due to well-formedness of $E$. Choose arbitrary
$\env \in \Sem\Gamma~\Env$. We want to prove that $\Sem
t~\env \in T$. Pick one particular instantiation of
$T_1,\ldots,T_n$ in equation~\eqref{nested-monstrosity}.
Let
\[
\Env'=(\Env\Updated\beta_1\mapsto T_1,\ldots,\beta_n\mapsto T_n).
\]
$\Env'$ is compatible with $E$ and satisfies $C$. Since
$\beta_1,\ldots,\beta_n\notin\FTV(\Gamma)$,
\[
\Sem\Gamma~\Env'=\Sem\Gamma~\Env\ni\env.
\]
By the antecedent $(\Gamma\vdash t:\rho\Given C)$,
\[
\Sem t~\env\in\Sem\rho~\Env'.
\]
Since $T_\alpha,T_1,\ldots,T_n$ are arbitrary, $\Sem t~\env\in T$.


\Par{S-rules of CT1}~

\infrule[S-Vacuous]
{}
{\emptyset\vdash\emptyset}

\infrule[S-Refl]
{E\vdash C}
{E\vdash C,\sigma\le\sigma}

\infrule[S-Bot]
{E\vdash C}
{E\vdash C, \Bot\le\tau}

\infrule[S-Top]
{E\vdash C}
{E\vdash C, \rho\le\Top}

\infrule[S-Arrow]
{E\vdash C, \rho_1\le\tau_1,\rho_2\le\tau_2}
{E\vdash C, \tau_1\R\rho_2 \le \rho_1\R\tau_2}

\infrule[S-Union]
{E\vdash C, \rho_1\le\tau,\rho_2\le\tau}
{E\vdash C, \rho_1\cup\rho_2 \le \tau}

\infrule[S-Intersect]
{E\vdash C, \rho\le\tau_1, \rho\le\tau_2}
{E\vdash C, \rho\le\tau_1\cap\tau_2}

\infrule[S-L0]
{
E,\alpha\in I\vdash C, \rho\le\tau
\andalso
\text{$\alpha$ occurs only in $\rho$}
}
{E\vdash C, (\All\alpha\rho)\le\tau}

\infrule[S-L1]
{
E,\alpha\in [\rho_1\cup\rho_2,\tau_1\cap\tau_2]\vdash
C, \rho\le\tau
\andalso
\text{$\alpha$ occurs only in $\rho$}
}
{E\vdash C, (\All{\alpha\in [\rho_1,\tau_1]}\rho)\le\tau}

\infrule[S-R]
{
E\vdash C,\rho\le\tau
\andalso
\text{$\alpha$ occurs only in $\tau$}
}
{E\vdash C, \rho\le(\All\alpha\tau)}


\infrule[S-Loner]
{
E\vdash C,\rho\le\tau
\andalso
\text{$\alpha$ fresh}
}
{
E,\alpha\in[\rho,\tau]\vdash C,\rho\le\alpha,\alpha\le\tau
}


\Par{Soundness of S-rules}~
\label{sound-S}


\textsc{S-Vacuous}: The empty prefix of interval bounds is
well-formed. Every statement in an empty collection is true.

\textsc{S-Refl}: The subset relation $\subseteq$ is reflexive.

\textsc{S-Bot}: $\{\bot\}$ is a subset of every type.

\textsc{S-Top}: Every type is a subset of $V-\{\Wrong\}$.

\textsc{S-Arrow}: $E$ is well-formed. Let $\Env$ be compatible
with $E$. Let
\[
f\in\Sem{\tau_1}~\Env\ \RT\ \Sem{\rho_2}~\Env.
\]
For every
\[
v\in\Sem{\rho_1}~\Env\subseteq\Sem{\tau_1}~\Env,
\]
we know
\[
f(v)\in\Sem{\rho_2}~\Env\subseteq\Sem{\tau_2}~\Env.
\]
The desired result follows:
\[
\Sem{\tau_1}~\Env\ \RT\ \Sem{\rho_2}~\Env
\qquad\subseteq\qquad
\Sem{\rho_1}~\Env\ \RT\ \Sem{\tau_2}~\Env
\]

\textsc{S-Union}, \textsc{S-Intersect}: Obvious, by definitions
of set union and intersection.

\textsc{S-L0}: This is a special case of \textsc{S-L1} with
$\rho_1=\Bot$ and $\tau_1=\Top$.

\textsc{S-L1}:
Let $\Env$ be a type environment compatible with $E$. Let
\begin{align*}
I_1 &= \Sem{[\rho_1,\tau_1]}~\Env,\\
I_2 &= \Sem{[\rho_1\cup\rho_2, \tau_1\cap\tau_2]}~\Env.
\end{align*}
Since $(E,\alpha\in [\rho_1\cup\rho_2, \tau_1\cap\tau_2])$ is
well-formed, $E$ is well-formed and $I_2\subseteq I_1$ is
nonempty. With any $T_\alpha\in I_2$,
\begin{samepage}
\begin{align*}
\Sem{\All{\alpha\in[\rho_1,\tau_1]}\rho}~\Env
&=\bigcap_{T\in I_1}\Sem\rho~(\Update\Env\alpha\mapsto T)\\
&\subseteq
\Sem\rho~(\Update\Env\alpha\mapsto T_\alpha)\\
&\subseteq
\Sem\tau~(\Update\Env\alpha\mapsto T_\alpha)\\
&=\Sem\tau~\Env,
\end{align*}
\end{samepage}%
where the last equality is due to $\alpha$ not being free in
$\tau$. So $\Env$ satisfies $(\All\alpha\rho)\le\tau$. Since
$\alpha$ is not free in $C$ and $(\Update\Env\alpha\mapsto
T_\alpha)$ satisfies $C$, $\Env$ satisfies $C$ as well.

\textsc{S-R}: Let $\Env$ be compatible with $E$. Then $\Env$
satisfies $C$. Choose arbitrary $T_\alpha\in\Type$. Since
$\alpha$ does not occur in $E$, the type environment
\[
\Env'=(\Update\Env\alpha\mapsto T_\alpha)
\]
is compatible with $E$. By the antecedent,
\[
\Sem\rho~\Env = \Sem\rho~\Env' \subseteq \Sem\tau~\Env'.
\]
Since $T_\alpha$ is arbitrary, we may conclude
\[
\Sem\rho~\Env
\subseteq
\bigcap_{T\in\Type}\Sem\tau~(\Update\Env\alpha\mapsto T)
=\Sem{\All\alpha\tau}~\Env.
\]

\textsc{S-Loner}: Let $\Env$ be compatible with $E$. By the
antecedent,
\[
\Sem\rho~\Env\subseteq\Sem\tau~\Env.
\]
Therefore the interval $\Sem{[\rho,\tau]}~\Env$ is nonempty, and
the prefix $(E,\alpha\in [\rho,\tau])$ is well-formed. Moreover,
\begin{align*}
\Sem\rho~\Env&\subseteq T_\alpha&
&\mbox{and}&
T_\alpha&\subseteq\Sem\tau~\Env
\end{align*}
for every $T_\alpha\in \Sem{[\rho,\tau]}~\Env$ by definition.
Hence the conclusion.


\section{Mixing F and CT1 for optional type arguments}

CT1 is friendlier than F for programming with impredicative
polymorphism, because the user does not have to provide type
arguments. However, we do not know whether CT1 subsumes F,
whether all terms well-typed in F remain well-typed in CT1 if we
leave out type applications. This lack of knowledge discourages a
commitment to CT1, but it does not prevent us from enjoying its
benefit. By mixing F and CT1 together, user program fragments
will not be problematic if they can be typed in F and not in CT1.

F consumes and produces F-judgements, while CT1 consumes and
produces S- and CT-judgements. To have rules from both systems in
the typing derivation of a single term, we need to make F- and
CT-judgements talk to each other by establishing some entailment
relations.

Going from F-judgements to CT-judgements is easy, because the
former are stronger than the latter.

\infrule[CT-F]
{\Gamma\vdash t : \sigma}
{\Gamma\vdash t : \sigma\Given\emptyset}

It is trickier to go from CT-judgements to F-judgements. Not only
do we have to resolve accumulated constraints (via \text{CT-S}
for example), we must also eliminate union, intersection and
interval-bounded universal type expressions from the type of a
term, so that F-rules can deal with it comfortably. Ascription
suffices.

\begin{samepage}
\begin{syntax}
t &\+=& t : \sigma &\mbox{ascription}
\end{syntax}%

\[
\Erase(t:\sigma)=t
\]
\end{samepage}

\infrule[F-Ascr]
{
\Gamma\vdash t:\rho\Given\emptyset
\andalso
\emptyset\vdash\rho\le\sigma
}
{\Gamma\vdash (t : \sigma) : \sigma}

The soundness of these rules is obvious after \S\ref{sound-F},
\ref{sound-CT} and \ref{sound-S}.


\section{Subtyping}

Records, variants, subtyping. Subsumption and supertype-bounded
quantification in F and CT1.


\section{Parametric types}

It may be possible to refine ``equal up to termination'' relation
in ``fast and loose reasoning'' to the non-transitive consistency
relation. Free theorems should hold. Parametric types are not
universal types.


\section{Category of types}
\label{hask}

Category theory has been applied to programming languages and is
useful to reason about data type generic programming (bananas et
co.). Types form a category.
\begin{itemize}
\item Objects are types.
\item Morphisms are triples $(f,T_1, T_2)$ where $f\in V\R V$ and
$f(T_1)\subseteq T_2$.
\item Composition of morphisms is function composition on the
first component:\\
$(f,T_2,T_3)\circ(g, T_1, T_2)=(f\circ g,T_1,T_3)$.
\end{itemize}
Each function in $V\R V$ gives rise to multiple morphisms. The
composition of morphisms is clearly associative and always
produces a morphism. The identity morphism on the object $T$ is
$(\Id_V, T, T)$, where $\Id_V$ is the identity function on $V$.

An endofunctor $F$ is a function mapping types to types and
morphisms to morphisms such that identity morphisms and
composition are preserved. If $F$ is contractive, then it has a
unique fixed point $T$. If we write $\Id_T$ for the identity
morphism $(\Id_V, T, T)$, then $(T,\Id_T)$ is both the initial
algebra and the final coalgebra. Lists \emph{are} streams.


\end{document}
